# Malware-Lookup-Service

### Problem Statement:

We have an HTTP proxy that is scanning traffic, looking for malware URLs. Before allowing HTTP connections to be made, this proxy asks a service that maintains several databases of malware URLs if the resource being requested is known to contain malware. Write a small web service, that responds to GET requests where the caller passes in a URL and the service responds with some information about that URL. The GET requests would look like this:
GET /v1/urlinfo/{resource_url_with_query_string}

### API initialisation and testing:

1.  Clone this git repository onto your local machine
2.	Create a python virtual environemnt and pip install -r requirements.txt
3.  Choose either the simple database lookup or machine learnning approach:

Database Lookup:

i. Initialize the sqlite database using db.create_all() within your python shell or while uncommenting the line from app.py. Subsequent runs do not need this line since it would override the data in the database and reinitialize

ii. Keep the flask app running in a separate terminal

iii. Add a few sample entries to your database from the test.py PUT method, along with their classification, on a separate terminal

iv. Test out whether the url submitted is malware or safe using the GET method on a separate terminal

Machine learnning:

i. Run the machine_learning.py file and make sure that the data utilized is in an csv format, exists in the same folder, and that the system is able to read it

ii. Test it using websites from both in and out of the database and check accuracy

iii. If the accuracy is  permissible, we can consider adding this functionality to the database lookup approach as well


### Additional Considerations:
● The size of the URL list could grow infinitely, how might you scale this beyond the memory capacity of the system?

● The number of requests may exceed the capacity of this system, how might you solve that?

● What are some strategies you might use to update the service with new URLs? Updates may be as many as 5000 URLs a day with updates arriving every 10 minutes.
